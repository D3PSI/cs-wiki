# Sequential Logic

# Introduction

The outputs of *sequential* logic depend on both current and prior input values. Hence, sequential logic has memory. Sequential logic might explicitly remember certain previous inputs, or it might distill the prior inputs into a smaller amount of information called the *state* of the system. The state of a digital sequential circuit is a set of bits called *state variables* that contain all the information about the past necessary to explain the future behavior of the circuit.

# Latches and Flip-Flops

The fundamental building block of memory is a *bistable* element, an element with two stable states. The figure shows a simple bistable element consisting of a pair of inverters connected in a loop. The same circuit is redrawn to emphasize the symmetry. The inverters are *cross-coupled*, meaning that the input of I1 is the output of I2 and vice versa. The circuit has no inputs, but it does have two outputs, $Q$ and $\bar{Q}$. Analyzing this circuit is different from analyzing a combinational circuit because it is cyclic: $Q$ depends on $\bar{Q}$, and $\bar{Q}$ depends on $Q$.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled.png)

Consider the two cases, $Q$ is 0 or $Q$ is 1. For each case the following consequences result:

- Case 1: $Q = 0$
    
    As shown in figure a), I2 receives a FALSE input, $Q$, so it produces a TRUE output on $\bar{Q}$. I1 receives a TRUE input, $\bar{Q}$, so it produces a FALSE output on $Q$. This is consistent with the original assumption that $Q = 0$, so the case is said to be *stable*.
    
- Case 2: $Q = 1$
    
    As shown in figure b), I2 receives a TRUE input and produces a FALSE output on $\bar{Q}$. I1 receives a FALSE input and produces a TRUE output on $Q$. This is again stable.
    

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%201.png)

Because the cross-coupled inverters have two stable states, $Q = 0$ and $Q = 1$, the circuit is said to be bistable. A subtle point is that the circuit has a third possible state with both outputs approximately halfway between 0 and 1. This is called a *metastable state* and will be discussed later.

An element with $N$ stable states conveys $\log_2 N$ bits of information, so a bistable element stores one bit. The state of the cross-coupled inverters is contained in one binary state variable, $Q$. The value of $Q$ tells us everything about the past that is necessary to explain the future behavior of the circuit. Specifically, if $Q = 0$, it will remain 0 forever, and if $Q = 1$, it will remain 1 forever. The circuit does have another node, $\bar{Q}$, but $\bar{Q}$ does not contain any additional information because if $Q$ is known, then $\bar{Q}$ is also known. On the other hand, $\bar{Q}$ is also an acceptable choice for the state variable.

When power is first applied to a sequential circuit, the initial state is unknown and usually unpredictable. it may differ each time the circuit is turned on.

Although the cross-coupled inverters can store a bit of information, they are not practical because the user has no inputs to control the state. However, other bistable elements, such as *latches* and *flip-flops*, provide inputs to control the value of the state variable.

## SR Latch

One of the simplest sequential circuits is the *SR latch*, which is composed of two cross-coupled $\text{NOR}$ gates as shown. The latch has two inputs, $S$ and $R$, and two outputs, $Q$ and $\bar{Q}$. The SR latch is similar to the cross-coupled inverters, but its state can be controlled through the $S$ and $R$ inputs, which *set* and *reset* the output $Q$.

A good way to understand an unfamiliar circuit is to work out its truth table, so let’s start there. Recall that a $\text{NOR}$ gate produces a FALSE output when either input is TRUE. Consider the four possible combinations of $R$ and $S$:

- Case 1: $R = 1, S = 0$
    
    N1 sees at least one TRUE input, $R$, so it produces a FALSE output on $Q$. N2 sees both $Q$ and $S$ FALSE, so it produces a TRUE output on $\bar{Q}$.
    
- Case 2: $R = 0, S = 1$
    
    N1 receives inputs of 0 and $\bar{Q}$. Because we don’t yet know $\bar{Q}$, we can’t determine the output $Q$. N2 receives at least one TRUE input, $S$, so it produces a FALSE output on $\bar{Q}$. Now we can revisit N1, knowing that both inputs are FALSE, so the output $Q$ is TRUE.
    
- Case 3: $R = 1, S = 1$
    
    N1 and N2 both see at least one TRUE input ($R$ or $S$), so each produces a FALSE output. Hence $Q$ and $\bar{Q}$ are both FALSE.
    
- Case 4: $R = 0, S = 0$
    
    N1 receives input of 0 and $\bar{Q}$. Because we don’t yet know $\bar{Q}$, we can’t determine the output. N2 receives inputs of 0 and $Q$. Because we don’t yet know $Q$, we can’t determine the output. Now we are stuck. This is reminiscent of the cross-coupled inverters. But we know that $Q$ must either be 0 or 1. So we should be able to solve the problem by checking what happens in each of these subcases.
    
    - Case 4a: $Q = 0$
        
        Because $S$ and $Q$ are FALSE, N2 produces a TRUE output on $\bar{Q}$, as shown in a). Now N1 receives one TRUE input, $\bar{Q}$, so its output, $Q$, is FALSE, just as we had assumed.
        
    - Case 4b: $Q = 1$
        
        Because $Q$ is TRUE, N2 produces a FALSE output on $\bar{Q}$, as shown in b). Now N1 receives two FALSE inputs, $R$ and $\bar{Q}$, so its output, $Q$, is TRUE, just as we had assumed.
        

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%202.png)

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%203.png)

Putting this all together, suppose $Q$ has some known prior value, which we shall call $Q_{\text{prev}}$, before we enter Case 4. $Q_{\text{prev}}$ is either 0 or 1, and represents the state of the system. When $R$ and $S$ are 0, $Q$ will remember this old value, $Q_{\text{prev}}$ and $\bar{Q}$ will be its complement, $\bar{Q}_{\text{prev}}$. The circuit has memory.

The truth table shown summarizes the four cases. The inputs $S$ and $R$ stand for *Set* and *Reset*. To *set* a bit means to make it TRUE. To *reset* a bit means to make it FALSE. The outputs, $Q$ and $\bar{Q}$, are normally complementary. When $R$ is asserted, $Q$ is reset to 0 and $\bar{Q}$ does the opposite. When $S$ is asserted, $Q$ is set to 1 and $\bar{Q}$ does the opposite. When neither input is asserted, $Q$ remembers its old value, $Q_{\text{prev}}$. Asserting both $S$and $R$ simultaneously does not make much sense because it means the latch should be set and reset at the same time, which is kind of impossible. The poor circuit has no other choice but to make both outputs 0, which makes no sense.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%204.png)

The SR latch is represented by the symbol shown. Using the symbol is again an application of abstraction and modularity. There are various ways to build an SR latch, such as using different logic gates or transistors. Nevertheless, any circuit element with the relationship specified by the above truth table and the symbol shown is called an SR latch.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%205.png)

Like the cross-coupled inverters, the SR latch is a bistable element with one bit of state stored in $Q$. However, the state can be controlled through the $S$ and $R$ inputs.

## D Latch

The SR latch is awkward because it behaves strangely when both inputs are asserted simultaneously. Moreover, the inputs conflate the issues of *what* and *when*. Asserting one of the inputs determines not only *what* the state should be but also *when* it should change. Circuit design becomes a lot easier when these questions are separated. The D latch in the figure solves these issues. It has two inputs. The *data* input, $D$, controls what the next state should be. The *clock* input, $\text{CLK}$, controls when the state should change.

Again, we can analyze the latch by writing the truth table, given in the figure. We notice that in all cases, $\bar{Q}$ is the complement of $Q$, as would seem logical. The D latch avoids the strange case of simultaneously asserted $R$ and $S$ inputs.

Putting it all together, we see that the clock controls when data flows through the latch. When $\text{CLK} = 1$, the latch is *transparent*. The data at $D$ flows through to $Q$ as if the latch were just a buffer. When $\text{CLK} = 0$, the latch is *opaque*. It blocks the new data from flowing through to $Q$, and $Q$ retains the old value. Hence, the D latch is sometimes called a *transparent latch* or a *level-sensitive latch*. The D latch symbol is given in c).

The D latch updates its state continuously while $\text{CLK} = 1$.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%206.png)

## D Flip-Flop

A *D flip-flop* can be built from two back-to-back D latches controlled by complementary clocks, as shown. The first latch, L1, is called the *master*. The second latch, L2, is called the *slave*. The node between them is named N1. Symbols for the D flip-flop are given in b) and c).

When $\text{CLK} = 0$, the master latch is transparent and the slave is opaque. Therefore, whatever value was at $D$ propagates through to N1. When $\text{CLK} = 1$, the master goes opaque and the slave becomes transparent. The value at N1 propagates through to $Q$, but N1 is cut off from $D$. hence, whatever value was at $D$ immediately before the clock rises from 0 to 1 gets copied to $Q$ immediately after the clock rises. At all other times, $Q$ retains its old value, because there is always an opaque latch blocking the path between $D$ and $Q$.

In other words, *a $D$ flip-flop copies $D$ to $Q$ on the rising edge of the clock, and remembers its state at all other times*. The rising edge of the clock is often just called the *clock edge* for brevity.The $D$ input specifies what the new state will be. The clock edge indicates when the state should be updated.

A D flip-flop is also known as a *master-slave flip-flop*, an *edge-triggered flip-flop*, or a *positive edge-triggered flip-flop*. The triangle in the symbols denotes an edge-triggered clock input.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%207.png)

## Register

An $N$-bit register is a bank of $N$ flip-flops that share a common $\text{CLK}$ input, so that all bits of the register are updated at the same time. Registers are the key building block of most sequential circuits. The figure shows the schematic and symbol for a four-bit register with inputs $D_{3:0}$ and outputs $Q_{3:0}$. $D_{3:0}$ and $Q_{3:0}$ are both 4-bit busses.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%208.png)

## Enabled Flip-Flop

An *enabled flip-flop* adds another input called $\text{EN}$ or ENABLE to determine whether data is loaded on the clock edge. When $\text{EN}$ is TRUE, the enabled flip-flop behaves like an ordinary D flip-flop. When $\text{EN}$ is FALSE, the enabled flip-flop ignores the clock and retains its state. Enabled flip-flops are useful when we wish to load a new value into the flip-flop only some of the time, rather than on every clock edge.

The figure shown two ways to construct an enabled flip-flop from a D flip-flop and an extra gate. In the first figure, an input multiplexer chooses whether to pass the value at $D$, if $\text{EN}$ is TRUE, or to recycle the old state from $Q$, if $\text{EN}$ is FALSE. In the second figure, the clock is *gated*. If $\text{EN}$ is TRUE, the $\text{CLK}$ input to the flip-flop toggles normally. If $\text{EN}$ is FALSE, the $\text{CLK}$ input is also FALSE and the flip-flop retains its old value. Notice that $\text{EN}$ must not change while $\text{CLK} = 1$, lest the flip-flop see a clock *glitch*. Generally, performing logic on the clock is a bad idea. Clock gating delays the clock and can cause timing errors, as we will see later.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%209.png)

## Resettable Flip-Flop

A *resettable flip-flop* adds another input called $\text{RESET}$. When $\text{RESET}$ is FALSE, the resettable flip-flop behaves like an ordinary D flip-flop. When $\text{RESET}$ is TRUE, the resettable flip-flop ignores $D$ and resets the output to 0. Resettable flip-flops are useful when we want to force a known state into all the flip-flops in a system when we first turn it on.

Such flip-flops may be *synchronously* or *asynchronously resettable*. Synchronously resettable flip-flops reset themselves only on the rising edge of the clock. Asynchronously resettable flip-flops reset themselves as soon as $\text{RESET}$ becomes TRUE, independent of the clock.

The figure shows how to construct a synchronously resettable flip-flop from an ordinary D flip-flop and an $\text{AND}$ gate. 

Asynchronously resettable flip-flops require modifying the internal structure of the flip-flop.

As one might imagine, settable flip-flops are also occasionally used. They load a 1 into the flip-flop when $\text{SET}$ is asserted, and they too come in synchronous and asynchronous flavors. Resettable and settable flip-flops may also have an enable input and may be grouped into $N$-bit registers.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2010.png)

## Transistor-Level Latch and Flip-Flop Designs

Latches and flip-flops require a large number of transistors when built from logic gates. But the fundamental role of a latch is to be transparent or opaque, much like a switch. Recall from [Introduction](Introduction%201ba015f9cd614446bdb4213e70a154d9.md) that a transmission gate is an efficient way to build a CMOS switch, so we might expect that we could take advantage of transmission gates to reduce the transistor count. 

A compact D latch can be constructed from a single transmission gate, as shown. 

This latch suffers from two major limitations:

- *floating output node*: when the latch is opaque, $Q$ is not held at its value by any gates. This $Q$ is called a *floating* or *dynamic* node. After some time, noise and charge leakage may disturb the value of $A$.
- *no buffers*: the lack of buffers has caused malfunctions on several commercial chips. A spike of noise that pulls $D$ to a negative voltage can turn on the nMOS transistor, making the latch transparent, even when $\text{CLK} = 0$. Likewise, a spike on $D$ above $V_{DD}$ can turn on the pMOS transistor even when $\text{CLK} = 0$. And the transmission gate is symmetric, so it could be driven backward with noise on $Q$ affecting the input $D$. The general rule is that neither the input of a transmission gate nor the state node of a sequential circuit should ever be exposed to the outside world, where noise is likely.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2011.png)

The figure shows a more robust 12-transistor D latch used on modern commercial chips. It is still built around a clocked transmission gate, but it adds inverters I1 and I2 to buffer the input and output. The state of the latch is held on node N1. Inverter I3 and the tristate buffer T1 provide feedback to turn N1 into a *static node*. If a small amount of noise occurs on N1 while $\text{CLK} = 0$, T1 will drive N1 back to a valid logic value.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2012.png)

The figure shows a D flip-flop constructed from two static latches controlled by $\overline{\text{CLK}}$ and $\text{CLK}$. Some redundant internal inverters have been removed, so the flip-flop requires only 20 transistors. 

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2013.png)

# Synchronous Logic Design

In general, sequential circuits include all circuits that are not combinational - that is, those whose output cannot be determined by simply looking at the current inputs.

## Unstable Circuits

This circuit, where three inverters are routed in series, feeding the output back as the input, is an example of an unstable circuit. 

Assume node $X$ is 0 initially. Then $Y = 1$, $Z = 0$ and hence $X = 1$, which is inconsistent with out initial assumption. The circuit has no stable state and is said to be *unstable* or *astable*.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2014.png)

Assume each inverter has a propagation delay of 1 ns. Then the timing diagram of the circuit looks as shown. Each node oscillates between 0 and 1 with a *period* of 6 ns. This circuit is called a *ring oscillator*.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2015.png)

## Race Conditions

Let’s examine a new D latch design with fewer gates. 

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2016.png)

This circuit has a *race condition*, as can be seen from the timing diagram shown. This race condition causes it to fail when certain gates are slower than others. Suppose $\text{CLK} = D = 1$. The latch is transparent and passes $D$ through to make $Q = 1$. Now, $\text{CLK}$ falls. The latch should remember its old value, keeping $Q = 1$. However, suppose the delay through the inverter from $\text{CLK}$ to $\overline{\text{CLK}}$ is rather long compared to the delays of the $\text{AND}$ and $\text{OR}$ gates. Then nodes N1 and $Q$ may both fall before $\overline{\text{CLK}}$ rises. In such a case, N2 will never rise, and $Q$ becomes stuck at 0.

This is an example of an *asynchronous* circuit design in which outputs are directly fed back to inputs. Asynchronous circuits are infamous for having race conditions where the behavior of the circuit depends on which of two paths through logic gates is fastest. One circuit may work, while a seemingly identical one built from gates with slightly different delays may not work. Or the circuit may work only at certain temperatures or voltages at which the delays are just right. These mistakes are extremely difficult to track down.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2017.png)

## Synchronous Sequential Circuits

The previous two examples contain loops called *cyclic paths*, in which outputs are fed directly back to inputs. They are sequential rather than combinational circuits. Combinational logic has no cyclic paths and no races. If inputs are applied to combinational logic, the outputs will always settle to the correct value within a propagation delay. However, sequential circuits with cyclic paths can have undesirable races or unstable behavior.

To avoid these problems, designers break the cyclic paths by inserting registers somewhere in the path, This transforms the circuit into a collection of combinational logic and registers. The registers contain the state of the system, which changes only at the clock edge, so we say the state is *synchronized* to the clock. If the clock is sufficiently slow, so that the inputs to all registers settle before the next clock edge, all races are eliminated. Adopting this discipline of always using registers in the feedback path leads us to the formal definition of a synchronous sequential circuit.

Recall that a circuit is defined by its input and output terminals and its functional and timing specifications. A sequential circuit has a finite set of discrete *states* $\{S_0, S_1,...,S_{k-1}\}$. A *synchronous sequential circuit* has a clock input, whose rising edges indicate a sequence of times at which state transitions occur. We often use the terms *current state* and *next state* to distinguish the state of the system at the present from the state to which it will enter on the next clock edge. The functional specification details the next state and the value of each output for each possible combination of current state and input values. The timing specification consists of an upper bound, $t_{pcq}$, and a lower bound, $t_{ccq}$, on the time from the rising edge of the clock until the *output* changes, as well as *setup* and *hold* times, $t_{\text{setup}}$ and $t_{\text{hold}}$, that indicate when the *inputs* must be stable relative to the rising edge of the clock.

The rules of *synchronous sequential circuit composition* teach us that a circuit is a synchronous sequential circuit if it consists of interconnected circuit elements such that 

- every circuit element is either a register or a combinational circuit
- at least one circuit element is a register
- all registers receive the same clock signal
- every cyclic path contains at least one register

Sequential circuits that are not synchronous are called *asynchronous*.

A flip-flop is the simplest synchronous sequential circuit, as shown.

We often call the current state variable $S$ and the next state variable $S'$.

Two other common types of synchronous sequential circuits are called finite state machines and pipelines.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2018.png)

## Synchronous and Asynchronous Circuits

Asynchronous design in theory is more general than synchronous design, because the timing of the system is not limited by clocked registers. Just as analog circuits are more general than digital circuits because analog circuits can use any voltage, asynchronous circuits are more general than synchronous circuits because they can use any kind of feedback. However, synchronous circuits have proved to be easier to design and use than asynchronous circuits, just as digital are easier than analog circuits. Despite decades of research on asynchronous circuits, virtually all digital systems are essentially synchronous.

Of course, asynchronous circuits are occasionally necessary when communicating between systems with different clocks or when receiving inputs at arbitrary times, just as analog circuits are necessary when communicating with the real world of continuous voltages. Furthermore, research in asynchronous circuits continues to generate interesting insights, some of which can improve synchronous circuits too.

# Finite State Machines

Synchronous sequential circuits can be drawn in the forms shown in the figure. These forms are called *finite state machines (FSMs)*. They get their name because a circuit with $k$ registers can be in one of a finite number ($2^k$) unique states. An FSM has $M$ inputs, $N$ outputs, and $k$ bits of state. It also receives a clock and, optionally, a reset signal. An FSM consists of two blocks of combinational logic, *next state logic* and *output logic*, and a register that stores the state. On each clock edge, the FSM advances to the next state, which was computed based on the current state and inputs. There are two general classes of finite state machines, characterized by their functional specifications. In *Moore machines (a))*, the outputs depend only on the current state of the machine. In *Mealy machines (b))*, the outputs depend on both the current state and the current inputs. Finite state machines provide a systematic way to design synchronous sequential circuits given a functional specification. 

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2019.png)

## FSM Design Example

Consider the problem of inventing a controller for a traffic light at a busy intersection. We install two traffic sensors, $T_A$ and $T_B$, on both roads each. Each sensor indicates TRUE if someone is present and FALSE if the street is empty. We also install two traffic lights, $L_A$ and $L_B$, to control traffic. Each light receives digital inpputs specifying whether it should be green, yellow or red. Hence, this FSM should have two inputs, $T_A$ and $T_B$, and two outputs, $L_A$ and $L_B$. The intersection with lights and sensors is shown in the figure. We provide a clock with a 5-second period. On each clock tick, the lights may change based on the traffic sensors. We also provide a reset button so that we can put the controller in a known initial state when turning it on.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2020.png)

A black box view of the state machine could look as shown.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2021.png)

We can sketch a *state transition diagram,* as shown, to indicate all the possible states of the system and the transitions between those states.

In a state transition diagram, circles represent states and arcs represent transitions between states. The transitions take place on the rising edge of the clock; we do not bother to show the clock on the diagram, because it is always present in a synchronous sequential circuit. Moreover, the clock simply controls when the transitions should occur, whereas the diagram indicates which transitions occur. The arc labeled Reset pointing from outer space into state S0 indicates that the system should enter that state upon reset, regardless of what previous state it was in. If a state has multiple arcs leaving it, the arcs are labeled to show what input triggers each transition. If a state has a single transition leaving it, that transition always occurs regardless of the inputs.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2022.png)

We can also rewrite this state transition diagram as a *state transition table*, which indicates, for each state and input, what the next state, $S'$ should be, as shown. Note that Reset is omitted from the table. Instead, we use resettable flip-flops that always to to state S0 on reset, independent of the inputs.

The state transition diagram is abstract in that it uses states labeled S0 through S3 and outputs labeled after their respective color. To build a real circuit, the states and outputs must be assigned *binary encodings*. 

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2023.png)

We choose simple encodings as shown.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2024.png)

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2025.png)

We update the state transition table to use these binary encodings, as shown. The revised state transition table is a truth table specifying the next state logic. It defines next state, $S'$, as a function of the current state, $S$, and the inputs. The revised output table is a truth table specifying the output logic. It defines the outputs, $L_A$ and $L_B$, as functions of the current state, $S$.

From this table, it is straightforward  to read off the Boolean equations for the next state in sum-of-products from.

$$
\begin{align*}
S_1' &= \bar{S}_1S_0 + S_1\bar{S}_0\bar{T}_B + S_1\bar{S}_0T_B \\
S_0' &= \bar{S}_1\bar{S}_0\bar{T}_A + S_1\bar{S}_0\bar{T}_B
\end{align*}
$$

The equations can be simplified further. We can then see that $S_1'$ reduces to an $\text{XOR}$ operation. The *next state equations* are as follows:

$$
\begin{align*}
S_1' &= S_1 \oplus S_0 \\
S_0' &= \bar{S}_1\bar{S}_0\bar{T}_A + S_1\bar{S}_0\bar{T}_B
\end{align*}
$$

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2026.png)

Similarly, we can write an *output table* indicating, for each state, what the output should be in that state. Again, its straightforward to read off and simplify the Boolean equations for the outputs. For example, observe that $L_{A1}$ is TRUE only on the rows where $S_1$ is TRUE. 

$$
\begin{align*}
L_{A1} &= S_1 \\
L_{A0} &= \bar{S}_1S_0 \\
L_{B1} &= \bar{S}_1 \\
L_{B0} &= S_1S_0
\end{align*}
$$

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2027.png)

Finally, we can draw our Moore FSM. First, we draw the 2-bit state register as shown in a). On each clock edge, the state register copies the next state, $S'_{1:0}$, to become the state, $S_{1:0}$. The state register receives a synchronous or asynchronous reset to initialize the FSM at startup. Then, we draw the next state logic, based on the above equations, which computes the next state, based on the current state and inputs, as shown in b). Finally, we draw the output logic, based on above equations, which computes the outputs based on the current state, as shown in c).

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2028.png)

The figure shows a timing diagram illustrating the traffic light controller going through a sequence of states. The diagram shows $\text{CLK}$, Reset, the inputs $T_A$ and $T_B$, next state $S'$, state $S$, and outputs $L_A$ and $L_B$. Arrows indicate causality.

The clock has a 5-second period, so the traffic lights change at most once every 5 seconds. When the finite state machine is first turned on, its state is unknown, as indicated by the question marks. Therefore, the system should be reset to put it into a known state. In this timing diagram, $S$ immediately resets to S0, indicating that asynchronously resettable flip-flops are being used.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2029.png)

## State Encodings

In the previous example, the state and output encodings were selected arbitrarily. A natural question is how to determine the encoding that produces the circuit with the fewest logic gates or the shortest propagation delay. Unfortunately, there is no simple way to find the best encoding except to try all possibilities, which is infeasible if the number of states is large.

One important decision in state encoding is the choice between binary encoding and one-hot encoding. With *binary encoding*, as was used in the traffic light controller example, each state is represented as a binary number. Because $K$ binary numbers can be represented by $\log_2K$ bits, a system with $K$ states only needs $\log_2K$ bits of state.

In *one-hot encoding*, a separate bit of state is used for each state. It is called one-hot because only one bit is “hot” or TRUE at any time. Each bit of state is stored in one flip-flop, so one-hot encoding requires more flip-flops than binary encoding. However, with one-hot encoding, the next-state and output logic is often simpler, so fewer gates are required.

A related encoding is the *one-cold* encoding, in which $K$ states are represented with $K$ bits, exactly one of which is FALSE.

## Moore and Mealy Machines

In Moore machines the output depends only on the state of the system. Hence, in state transition diagrams for Moore machines, the outputs are labeled in the circles. Recall that Mealy machines are much like Moore machines, but the outputs can depend on inputs as well as the current state. Hence, in state transition diagrams for Mealy machines, the outputs are labeled on the arcs instead of in the circles. The block of combinational logic that computes the outputs uses the current state and inputs, as shown in the schematic of a Mealy machine above.

Example state transition diagrams for Moore (a)) and Mealy (b)) machines are shown.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2030.png)

## Factoring State Machines

Designing complex FSMs is often easier if they can be broken down into multiple interacting simpler state machines such that the output of some machines is the input of others. This application of hierarchy and modularity is called factoring of state machines.

As shown in the diagrams, where a) is the unfactored, and b) the factored version of the same circuit.

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2031.png)

![Untitled](Sequential%20Logic%2042c224c8465c4576ac93922cb2672120/Untitled%2032.png)

## FSM Review

Finite state machines are a powerful way to systematically design sequential circuits from a written specification. Use the following procedure to design an FSM:

- identify the inputs and outputs
- sketch a state transition diagram
- for a Moore machine:
    - write a state transition table
    - write an output table
- for a Mealy machine:
    - write a combined state transition and output table
- select state encodings - selection affects the hardware design
- write Boolean equations for the next state and output logic.
- sketch the circuit schematic

# Timing of Sequential Logic

# Parallelism